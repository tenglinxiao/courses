###############################
# White Elephant Configuration
###############################

# Base path in Hadoop where files will be stored
job.root=/user/tenglinxiao/output

# Base path where Hadoop logs are stored.
logs.root=/jthistory/version-1

# How many Hadoop jobs to run concurrently.  Logs are assumed to be divided
# by day.  A Hadoop job will be created for each day to process.  These jobs
# are run concurrently to make the whole task finish faster.
job.concurrency=20

# How many days of log data to process.
num.days=15

# Always process the last n days of log data, even when processing data incrementally.
# This is in case recent log data is partial.
num.days.forced=1

# Where should parsed logs be stored.
jobs.output.path=/user/tenglinxiao/output/parsed-logs

# Where should parsed confs be stored
confs.output.path=/user/tenglinxiao/output/parsed-confs

# Where should aggregated usage data be stored
usage.output.path=/user/tenglinxiao/output/usage-per-hour

# Names of Hadoop clusters to process logs for.
cluster.names=ares-jt.vip.ebay.com_1390306900405_

# Whether using increment mode.
incremental=false

#######################
# Hadoop Configuration
#######################

hadoop-conf.mapred.max.split.size=100000000
hadoop-conf.mapreduce.input.fileinputformat.split.maxsize=100000000
#hadoop-conf.io.compression.codecs=org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec
#hadoop-conf.mapred.compress.map.output=true
#hadoop-conf.mapred.map.output.compression.codec=com.hadoop.compression.lzo.LzoCodec

# TODO make sure to set your ugi
hadoop-conf.hadoop.job.ugi=username,hadoop