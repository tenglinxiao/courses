Meta VERSION="1" .
Job JOBID="job_201402141100_0017" JOBNAME="src/main/resources/job\.properties-usage-per-hour-ares-jt\.vip\.ebay\.com_1390306900405_-2014-01" USER="tenglinxiao" SUBMIT_TIME="1392378731630" JOBCONF="hdfs://localhost/tmp/hadoop-tenglinxiao/mapred/staging/tenglinxiao/\.staging/job_201402141100_0017/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" WORKFLOW_ID="" WORKFLOW_NAME="" WORKFLOW_NODE_NAME="" WORKFLOW_ADJACENCIES="" WORKFLOW_TAGS="" .
Job JOBID="job_201402141100_0017" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201402141100_0017" LAUNCH_TIME="1392378731708" TOTAL_MAPS="1" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201402141100_0017_m_000002" TASK_TYPE="SETUP" START_TIME="1392378731834" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201402141100_0017_m_000002" TASK_ATTEMPT_ID="attempt_201402141100_0017_m_000002_0" START_TIME="1392378732117" TRACKER_NAME="tracker_angelfish:localhost/127\.0\.0\.1:57781" HTTP_PORT="50060" LOCALITY="OFF_SWITCH" AVATAAR="VIRGIN" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201402141100_0017_m_000002" TASK_ATTEMPT_ID="attempt_201402141100_0017_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1392378734385" HOSTNAME="/default-rack/angelfish" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(65539)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(86749184)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(90)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62521344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(970514432)]}" .
Task TASKID="task_201402141100_0017_m_000002" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1392378734548" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(65539)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(86749184)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(90)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62521344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(970514432)]}" .
Job JOBID="job_201402141100_0017" JOB_STATUS="RUNNING" .
Task TASKID="task_201402141100_0017_m_000000" TASK_TYPE="MAP" START_TIME="1392378734549" SPLITS="/default-rack/angelfish" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201402141100_0017_m_000000" TASK_ATTEMPT_ID="attempt_201402141100_0017_m_000000_0" START_TIME="1392378734552" TRACKER_NAME="tracker_angelfish:localhost/127\.0\.0\.1:57781" HTTP_PORT="50060" LOCALITY="NODE_LOCAL" AVATAAR="VIRGIN" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201402141100_0017_m_000000" TASK_ATTEMPT_ID="attempt_201402141100_0017_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1392378743426" HOSTNAME="/default-rack/angelfish" STATE_STRING="" COUNTERS="{(Job Analysis)(Job Analysis)[(Status SUCCESS)(Status SUCCESS)(12096)][(Status KILLED)(Status KILLED)(2786)][(Status FAILED)(Status FAILED)(2)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(7368148)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2317076)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(7367966)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(2251505)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(1)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(303763456)][(SPILLED_RECORDS)(Spilled Records)(25230)][(MAP_OUTPUT_BYTES)(Map output bytes)(2201039)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(6300)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(202768384)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(970514432)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(25230)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(182)]}" .
Task TASKID="task_201402141100_0017_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1392378743595" COUNTERS="{(Job Analysis)(Job Analysis)[(Status SUCCESS)(Status SUCCESS)(12096)][(Status KILLED)(Status KILLED)(2786)][(Status FAILED)(Status FAILED)(2)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(7368148)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2317076)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(7367966)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(2251505)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(1)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(303763456)][(SPILLED_RECORDS)(Spilled Records)(25230)][(MAP_OUTPUT_BYTES)(Map output bytes)(2201039)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(6300)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(202768384)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(970514432)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(25230)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(182)]}" .
Task TASKID="task_201402141100_0017_r_000000" TASK_TYPE="REDUCE" START_TIME="1392378743597" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201402141100_0017_r_000000" TASK_ATTEMPT_ID="attempt_201402141100_0017_r_000000_0" START_TIME="1392378743601" TRACKER_NAME="tracker_angelfish:localhost/127\.0\.0\.1:57781" HTTP_PORT="50060" LOCALITY="OFF_SWITCH" AVATAAR="VIRGIN" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201402141100_0017_r_000000" TASK_ATTEMPT_ID="attempt_201402141100_0017_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1392378751725" SORT_FINISHED="1392378752473" FINISH_TIME="1392378757660" HOSTNAME="/default-rack/angelfish" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.lib\.output\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(4631)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(2251505)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2316959)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(4631)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(43)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2251505)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(134602752)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(43)][(SPILLED_RECORDS)(Spilled Records)(25230)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(5060)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62521344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(983560192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(25230)]}" .
Task TASKID="task_201402141100_0017_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1392378757899" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.lib\.output\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(4631)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(2251505)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2316959)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(4631)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(43)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2251505)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(134602752)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(43)][(SPILLED_RECORDS)(Spilled Records)(25230)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(5060)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62521344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(983560192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(25230)]}" .
Task TASKID="task_201402141100_0017_m_000001" TASK_TYPE="CLEANUP" START_TIME="1392378757900" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201402141100_0017_m_000001" TASK_ATTEMPT_ID="attempt_201402141100_0017_m_000001_0" START_TIME="1392378757909" TRACKER_NAME="tracker_angelfish:localhost/127\.0\.0\.1:57781" HTTP_PORT="50060" LOCALITY="OFF_SWITCH" AVATAAR="VIRGIN" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201402141100_0017_m_000001" TASK_ATTEMPT_ID="attempt_201402141100_0017_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1392378760814" HOSTNAME="/default-rack/angelfish" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(65539)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(86847488)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(100)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62521344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(971567104)]}" .
Task TASKID="task_201402141100_0017_m_000001" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1392378760918" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(65539)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(86847488)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(100)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62521344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(971567104)]}" .
Job JOBID="job_201402141100_0017" FINISH_TIME="1392378760919" JOB_STATUS="SUCCESS" FINISHED_MAPS="1" FINISHED_REDUCES="1" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(Job Analysis)(Job Analysis)[(Status SUCCESS)(Status SUCCESS)(12096)][(Status KILLED)(Status KILLED)(2786)][(Status FAILED)(Status FAILED)(2)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(7367966)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(7368148)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2317076)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(2251505)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(1)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(303763456)][(SPILLED_RECORDS)(Spilled Records)(25230)][(MAP_OUTPUT_BYTES)(Map output bytes)(2201039)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(202768384)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(6300)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(970514432)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(182)][(MAP_OUTPUT_RECORDS)(Map output records)(25230)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)]}" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.lib\.output\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(4631)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(2251505)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(2316959)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(4631)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(43)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2251505)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(134602752)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(43)][(SPILLED_RECORDS)(Spilled Records)(25230)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62521344)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(5060)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(983560192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(25230)]}" COUNTERS="{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(14047)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(1)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(1)][(DATA_LOCAL_MAPS)(Data-local map tasks)(1)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(14059)]}{(org\.apache\.hadoop\.mapreduce\.lib\.output\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(4631)]}{(Job Analysis)(Job Analysis)[(Status SUCCESS)(Status SUCCESS)(12096)][(Status KILLED)(Status KILLED)(2786)][(Status FAILED)(Status FAILED)(2)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(7367966)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(2251505)][(HDFS_BYTES_READ)(HDFS_BYTES_READ)(7368148)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(4634035)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(4631)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(43)][(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(2251505)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(1)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2251505)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(438366208)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(43)][(SPILLED_RECORDS)(Spilled Records)(50460)][(MAP_OUTPUT_BYTES)(Map output bytes)(2201039)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(265289728)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(11360)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(1954074624)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(182)][(MAP_OUTPUT_RECORDS)(Map output records)(25230)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(25230)]}" .
